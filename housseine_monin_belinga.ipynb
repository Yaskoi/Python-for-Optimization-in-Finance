{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d60ae20",
   "metadata": {},
   "source": [
    "# Python for Optimization in Finance\n",
    "\n",
    "---\n",
    "\n",
    "**A comprehensive analysis of portfolio optimization strategies using Python**\n",
    "\n",
    "*Financial Engineering & Quantitative Analysis*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dd69af",
   "metadata": {},
   "source": [
    "## Data Overview\n",
    "\n",
    "### Available Datasets\n",
    "\n",
    "| **Dataset** | **Description** | **Count** |\n",
    "|-------------|-----------------|-----------|\n",
    "| **ETFs** | Anonymized ETF data since 2019 | **105** |\n",
    "| **Financial Assets** | Historical prices of main asset classes | **14** |\n",
    "\n",
    "### Main Financial Assets Categories\n",
    "\n",
    "- **Regional Sovereign Bonds**\n",
    "- **High Yield (HY) Bonds** \n",
    "- **Commodities**\n",
    "- **Dollar Index**\n",
    "\n",
    "### Allocation Strategies\n",
    "\n",
    " **Two distinct allocation methodologies will be analyzed:**\n",
    "\n",
    "1. **Fixed Allocation Strategy**\n",
    "   - Static allocation among the 105 ETFs\n",
    "   - Constant throughout the entire period\n",
    "\n",
    "2. **Dynamic Allocation Strategy**\n",
    "   - Variable allocation among the 105 ETFs\n",
    "   - Changes over time but with low frequency\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f440c70",
   "metadata": {},
   "source": [
    "## Project Objectives\n",
    "\n",
    "### Key Research Questions\n",
    "\n",
    "1. **ETF Classification Analysis**\n",
    "   - Classify ETFs based on various risk metrics, relationships, and performance criteria\n",
    "   - Identify patterns and clustering among the 105 ETFs\n",
    "\n",
    "2. **Asset Class Relationship Mapping**\n",
    "   - Establish relationships between ETFs and main asset classes\n",
    "   - Identify each ETF's correlation with Regional Sovereign Bonds, HY Bonds, Commodities, and Dollar Index\n",
    "\n",
    "3. **Risk Assessment**\n",
    "   - Determine the risk ranges among the ETFs\n",
    "   - Analyze risk distribution and identify outliers\n",
    "\n",
    "4. **Mystery Allocation Analysis**\n",
    "   - Identify the composition of both fixed and dynamic mystery allocations\n",
    "   - Quantify uncertainty in the allocation results\n",
    "   - Compare performance of both allocation strategies\n",
    "\n",
    "5. **Critical Analysis & Validation**\n",
    "   - Comment on results and methodology\n",
    "   - Identify potential biases in the analysis\n",
    "   - Assess coverage of asset classes among the ETFs\n",
    "   - Highlight any forgotten or underrepresented asset classes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "37857a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ numpy déjà installé\n",
      "✓ pandas déjà installé\n",
      "✓ matplotlib déjà installé\n",
      "✓ scipy déjà installé\n",
      "Installation terminée!\n"
     ]
    }
   ],
   "source": [
    "# ┌─────────────────────────────────────┐\n",
    "# │    INSTALLATION DES DÉPENDANCES     │ \n",
    "# └─────────────────────────────────────┘\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Liste des bibliothèques à installer\n",
    "packages = ['numpy', 'pandas', 'matplotlib', 'scipy']\n",
    "\n",
    "# Installation des packages\n",
    "for package in packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"✓ {package} déjà installé\")\n",
    "    except ImportError:\n",
    "        print(f\"Installation de {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "print(\"Installation terminée!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1d2c8812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ┌─────────────────────────────────────┐\n",
    "# │    IMPORTATION DES BIBLIOTHÈQUES    │ \n",
    "# └─────────────────────────────────────┘\n",
    "\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import pathlib\n",
    "import datetime as dt\n",
    "from typing import Tuple, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.optimize import minimize, LinearConstraint, Bounds\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5c2ef938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répertoire de sortie configuré: c:\\Users\\emman\\Documents\\GitHub\\Python-for-Optimization-in-Finance\\results\n"
     ]
    }
   ],
   "source": [
    "# ┌─────────────────────────────────────┐\n",
    "# │     CONFIGURATION GLOBALE           │ \n",
    "# └─────────────────────────────────────┘\n",
    "\n",
    "# Configuration du répertoire de sortie\n",
    "OUTPUT_DIR = \"results\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Répertoire de sortie configuré: {os.path.abspath(OUTPUT_DIR)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2ca2da9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ┌─────────────────────────────────────┐\n",
    "# │      FONCTIONS UTILITAIRES I/O      │ \n",
    "# └─────────────────────────────────────┘\n",
    "\n",
    "def load_csv_safely(path: str, parse_dates: bool = True, skip_rows: int = None) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Charge un CSV de façon robuste :\n",
    "    - détection automatique des lignes à ignorer (métadonnées)\n",
    "    - détection de la colonne 'Date' (ou première colonne si doute)\n",
    "    - conversion en datetime + index\n",
    "    - enlève colonnes vides / dupliquées\n",
    "    \n",
    "    Args:\n",
    "        path: chemin vers le fichier CSV\n",
    "        parse_dates: si True, convertit la première colonne en datetime\n",
    "        skip_rows: nombre de lignes à ignorer (si None, détection automatique)\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"[WARN] Fichier introuvable : {path}\")\n",
    "        return None\n",
    "    \n",
    "    # Détection automatique des lignes à ignorer\n",
    "    if skip_rows is None:\n",
    "        # Lecture des premières lignes pour détecter le header\n",
    "        with open(path, 'r') as f:\n",
    "            lines = [f.readline().strip() for _ in range(10)]\n",
    "        \n",
    "        # Recherche de la ligne contenant \"Date\" ou des dates\n",
    "        for i, line in enumerate(lines):\n",
    "            if 'date' in line.lower() or 'time' in line.lower():\n",
    "                skip_rows = i\n",
    "                break\n",
    "        else:\n",
    "            skip_rows = 0\n",
    "    \n",
    "    # Chargement du fichier\n",
    "    df = pd.read_csv(path, skiprows=skip_rows)\n",
    "    \n",
    "    # Nettoyage des colonnes vides au début\n",
    "    df = df.dropna(how='all', axis=1)\n",
    "    df = df.dropna(how='all', axis=0)\n",
    "    \n",
    "    # Tentative de détection de la colonne date\n",
    "    date_col_candidates = [c for c in df.columns if 'date' in c.lower() or 'time' in c.lower()]\n",
    "    \n",
    "    if parse_dates:\n",
    "        if date_col_candidates:\n",
    "            date_col = date_col_candidates[0]\n",
    "        else:\n",
    "            date_col = df.columns[0]  # par défaut\n",
    "        \n",
    "        # Conversion en datetime\n",
    "        df[date_col] = pd.to_datetime(df[date_col], errors=\"coerce\", dayfirst=True)\n",
    "        df = df.dropna(subset=[date_col]).sort_values(date_col).set_index(date_col)\n",
    "        df = df[~df.index.duplicated(keep=\"first\")]\n",
    "    \n",
    "    # Nettoyage final\n",
    "    df = df.loc[:, ~df.columns.duplicated()]\n",
    "    df = df.dropna(how=\"all\", axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "70264572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ┌─────────────────────────────────────┐\n",
    "# │       CALCUL DES RENDEMENTS         │ \n",
    "# └─────────────────────────────────────┘\n",
    "\n",
    "def to_returns(prices: pd.DataFrame,\n",
    "               kind: str = \"log\",\n",
    "               periods: int = 1,\n",
    "               dropna: object = True,\n",
    "               coerce_numeric: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calcule les rendements à partir d'une table de prix/NAV.\n",
    "\n",
    "    Paramètres:\n",
    "    - prices: DataFrame indexé (date) avec les prix/NAV\n",
    "    - kind: 'log' ou 'simple'\n",
    "    - periods: nombre de périodes pour le shift (1 = t / t-1)\n",
    "    - dropna: True (drop rows all-NaN), False (ne rien faire), or 'any'/'all' to pass to dropna(how=...)\n",
    "    - coerce_numeric: si True, convertit les colonnes en numériques (non-convertibles -> NaN puis supprimées)\n",
    "\n",
    "    Retourne un DataFrame de rendements avec les mêmes colonnes numériques et index trié.\n",
    "    \"\"\"\n",
    "    # validations basiques\n",
    "    if kind not in (\"log\", \"simple\"):\n",
    "        raise ValueError(\"kind must be 'log' or 'simple'\")\n",
    "    if not isinstance(prices, pd.DataFrame):\n",
    "        raise TypeError(\"prices must be a pandas DataFrame\")\n",
    "    if not (isinstance(periods, int) and periods >= 1):\n",
    "        raise ValueError(\"periods must be a positive integer\")\n",
    "\n",
    "    # trier l'index pour l'ordre temporel\n",
    "    px = prices.sort_index()\n",
    "\n",
    "    # conversion/coercion des colonnes en numérique si demandé\n",
    "    if coerce_numeric:\n",
    "        px = px.apply(pd.to_numeric, errors=\"coerce\")\n",
    "        # supprimer les colonnes devenues entièrement NaN\n",
    "        px = px.loc[:, px.notna().any(axis=0)]\n",
    "    else:\n",
    "        non_numeric = [c for c in px.columns if not np.issubdtype(px[c].dtype, np.number)]\n",
    "        if non_numeric:\n",
    "            raise TypeError(f\"Non-numeric columns present: {non_numeric}\")\n",
    "\n",
    "    # si pas assez d'observations pour calculer les rendements, renvoyer une structure vide cohérente\n",
    "    if px.shape[0] <= periods:\n",
    "        rets = px.iloc[0:0].astype(float)\n",
    "        return rets\n",
    "\n",
    "    # pour les rendements log, remplacer les prix <= 0 par NaN (log indéfini) et prévenir\n",
    "    if kind == \"log\":\n",
    "        mask_nonpos = (px <= 0)\n",
    "        if mask_nonpos.any().any():\n",
    "            import warnings\n",
    "            warnings.warn(\"Zero or negative price(s) found; corresponding log returns will be NaN.\")\n",
    "            px = px.mask(mask_nonpos)\n",
    "        rets = np.log(px / px.shift(periods))\n",
    "    else:\n",
    "        rets = px.pct_change(periods=periods)\n",
    "\n",
    "    # gestion flexible du dropna\n",
    "    if dropna is True:\n",
    "        rets = rets.dropna(how=\"all\")\n",
    "    elif dropna in (\"any\", \"all\"):\n",
    "        rets = rets.dropna(how=dropna)\n",
    "    # si dropna est False ou None, on renvoie tout tel quel\n",
    "\n",
    "    return rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3f3588c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ┌─────────────────────────────────────┐\n",
    "# │    ANNUALISATION DES STATISTIQUES   │ \n",
    "# └─────────────────────────────────────┘\n",
    "\n",
    "def annualize_mean_vol(rets: pd.DataFrame, periods_per_year: int = 252) -> Tuple[pd.Series, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Annualise la moyenne et la matrice de covariance des rendements.\n",
    "\n",
    "    Args:\n",
    "        rets: DataFrame des rendements (doit être des rendements simples, pas des log-returns)\n",
    "        periods_per_year: nombre de périodes par an (252 pour les jours ouvrables)\n",
    "\n",
    "    Returns:\n",
    "        mu: Series des rendements moyens annualisés\n",
    "        cov: DataFrame de la matrice de covariance annualisée\n",
    "    \"\"\"\n",
    "    if not isinstance(rets, pd.DataFrame):\n",
    "        raise TypeError(\"rets must be a pandas DataFrame\")\n",
    "    if rets.empty:\n",
    "        return pd.Series(dtype=float), pd.DataFrame(dtype=float)\n",
    "\n",
    "    # Calculs (en ignorant les colonnes entièrement NaN)\n",
    "    rets_clean = rets.loc[:, rets.notna().any(axis=0)]\n",
    "    mu = rets_clean.mean() * periods_per_year\n",
    "    cov = rets_clean.cov() * periods_per_year\n",
    "\n",
    "    # Avertir si des NaN subsistent\n",
    "    if mu.isna().any() or cov.isna().any().any():\n",
    "        import warnings\n",
    "        warnings.warn(\"NaN values present in annualized mean or covariance; consider filtering assets.\")\n",
    "\n",
    "    return mu, cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c2f99442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ┌─────────────────────────────────────┐\n",
    "# │       CONVERSION NUMÉRIQUE          │ \n",
    "# └─────────────────────────────────────┘\n",
    "\n",
    "def ensure_numeric(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convertit toutes les colonnes possibles en numérique.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame à convertir\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame avec colonnes converties en numérique (NaN pour les valeurs non convertibles)\n",
    "    \"\"\"\n",
    "    for c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ff0569d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ┌─────────────────────────────────────┐\n",
    "# │      MÉTRIQUES DE PERFORMANCE       │ \n",
    "# └─────────────────────────────────────┘\n",
    "\n",
    "@dataclass\n",
    "class PortfolioReport:\n",
    "    \"\"\"\n",
    "    Contient des métriques standard d'évaluation d'un portefeuille.\n",
    "    \n",
    "    Attributes:\n",
    "        cagr: Taux de croissance annuel composé\n",
    "        vol: Volatilité annualisée\n",
    "        sharpe: Ratio de Sharpe\n",
    "        maxdd: Maximum Drawdown\n",
    "        var_95: Value at Risk à 95%\n",
    "        es_95: Expected Shortfall à 95%\n",
    "    \"\"\"\n",
    "    cagr: float\n",
    "    vol: float\n",
    "    sharpe: float\n",
    "    maxdd: float\n",
    "    var_95: float\n",
    "    es_95: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e79df09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ┌─────────────────────────────────────┐\n",
    "# │      CALCUL DES STATISTIQUES        │ \n",
    "# └─────────────────────────────────────┘\n",
    "\n",
    "def compute_performance_stats(rets: pd.Series,\n",
    "                              rf: float = 0.0,\n",
    "                              periods_per_year: int = 252) -> PortfolioReport:\n",
    "    \"\"\"\n",
    "    Calcule des statistiques classiques sur une série de rendements (Series).\n",
    "    \n",
    "    Args:\n",
    "        rets: Série de rendements\n",
    "        rf: Taux sans risque (par défaut 0.0)\n",
    "        periods_per_year: Nombre de périodes par an (252 pour les jours ouvrables)\n",
    "    \n",
    "    Returns:\n",
    "        PortfolioReport avec toutes les métriques calculées\n",
    "    \n",
    "    Métriques calculées:\n",
    "        - CAGR: Taux de croissance annuel composé\n",
    "        - Volatilité annualisée\n",
    "        - Sharpe: (mu - rf) / vol\n",
    "        - Max Drawdown: Perte maximale depuis un pic\n",
    "        - VaR et ES 95%: Value at Risk et Expected Shortfall historiques\n",
    "    \"\"\"\n",
    "    rets = rets.dropna()\n",
    "    if rets.empty:\n",
    "        return PortfolioReport(np.nan, np.nan, np.nan, np.nan, np.nan, np.nan)\n",
    "\n",
    "    # CAGR approximé via cumprod des rendements\n",
    "    # Formule robuste : cumprod(1+r)^(annualisation) - 1\n",
    "    cum = (1 + rets).cumprod()\n",
    "    n_years = len(rets) / periods_per_year\n",
    "    cagr = cum.iloc[-1] ** (1.0 / n_years) - 1.0 if n_years > 0 else np.nan\n",
    "\n",
    "    # Volatilité annualisée\n",
    "    vol = rets.std() * np.sqrt(periods_per_year)\n",
    "\n",
    "    # Ratio de Sharpe (rendement ajusté du risque)\n",
    "    mu_ann = rets.mean() * periods_per_year\n",
    "    sharpe = (mu_ann - rf) / vol if vol > 0 else np.nan\n",
    "\n",
    "    # Maximum Drawdown\n",
    "    rolling_max = cum.cummax()\n",
    "    drawdown = cum / rolling_max - 1.0\n",
    "    maxdd = drawdown.min()\n",
    "\n",
    "    # VaR / ES 95% (approche historique)\n",
    "    q = rets.quantile(0.05)\n",
    "    var_95 = -q\n",
    "    es_95 = -rets[rets <= q].mean() if (rets <= q).any() else np.nan\n",
    "\n",
    "    return PortfolioReport(cagr, vol, sharpe, maxdd, var_95, es_95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5892c6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ┌─────────────────────────────────────┐\n",
    "# │    OPTIMISATION MARKOWITZ (MVO)     │ \n",
    "# └─────────────────────────────────────┘\n",
    "\n",
    "def _min_var_given_return(mu, cov, target_ret, w_bounds, allow_short=False):\n",
    "    \"\"\"\n",
    "    Résout le portefeuille de variance minimale pour un rendement cible donné.\n",
    "    \n",
    "    Problème d'optimisation: min w'Σw  s.c.  μ'w = target_ret, sum w=1, bounds\n",
    "    \n",
    "    Args:\n",
    "        mu: vecteur des rendements moyens\n",
    "        cov: matrice de covariance\n",
    "        target_ret: rendement cible\n",
    "        w_bounds: tuple (lower_bounds, upper_bounds)\n",
    "        allow_short: permet les positions courtes (non utilisé actuellement)\n",
    "        \n",
    "    Returns:\n",
    "        Résultat d'optimisation scipy avec attributs success, x, fun, etc.\n",
    "    \"\"\"\n",
    "    n = len(mu)\n",
    "    mu = np.asarray(mu)\n",
    "    cov = np.asarray(cov)\n",
    "    \n",
    "    def obj(w): \n",
    "        return w @ cov @ w\n",
    "    \n",
    "    # Contraintes: somme = 1 et rendement = target\n",
    "    cons = [\n",
    "        {\"type\": \"eq\", \"fun\": lambda w: np.sum(w) - 1.0},\n",
    "        {\"type\": \"eq\", \"fun\": lambda w: mu @ w - target_ret},\n",
    "    ]\n",
    "    \n",
    "    lb, ub = w_bounds\n",
    "    bounds = Bounds(lb, ub)\n",
    "    w0 = np.full(n, 1.0 / n)  # Poids équipondérés comme point de départ\n",
    "    \n",
    "    res = minimize(obj, w0, method=\"SLSQP\", bounds=bounds, constraints=cons)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cf5d3ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ┌─────────────────────────────────────┐\n",
    "# │      OPTIMISATION MAX SHARPE        │ \n",
    "# └─────────────────────────────────────┘\n",
    "\n",
    "def _max_sharpe(mu, cov, rf, w_bounds):\n",
    "    \"\"\"\n",
    "    Résout le portefeuille de ratio de Sharpe maximal.\n",
    "    \n",
    "    Problème d'optimisation: max (μ'w - rf) / sqrt(w'Σw) <=> min -Sharpe\n",
    "    s.c. sum w=1, bounds\n",
    "    \n",
    "    Args:\n",
    "        mu: vecteur des rendements moyens\n",
    "        cov: matrice de covariance  \n",
    "        rf: taux sans risque\n",
    "        w_bounds: tuple (lower_bounds, upper_bounds)\n",
    "        \n",
    "    Returns:\n",
    "        Résultat d'optimisation scipy avec attributs success, x, fun, etc.\n",
    "    \"\"\"\n",
    "    n = len(mu)\n",
    "    mu = np.asarray(mu)\n",
    "    cov = np.asarray(cov)\n",
    "\n",
    "    def neg_sharpe(w):\n",
    "        ret = mu @ w\n",
    "        vol = math.sqrt(max(w @ cov @ w, 0))  # Protection contre variance négative\n",
    "        return -(ret - rf) / vol if vol > 0 else 1e9\n",
    "\n",
    "    cons = [{\"type\": \"eq\", \"fun\": lambda w: np.sum(w) - 1.0}]\n",
    "    lb, ub = w_bounds\n",
    "    bounds = Bounds(lb, ub)\n",
    "    w0 = np.full(n, 1.0 / n)\n",
    "    \n",
    "    res = minimize(neg_sharpe, w0, method=\"SLSQP\", bounds=bounds, constraints=cons)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5206b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ┌─────────────────────────────────────┐\n",
    "# │   PORTEFEUILLE VARIANCE MINIMALE    │ \n",
    "# └─────────────────────────────────────┘\n",
    "\n",
    "def _global_min_var(cov, w_bounds):\n",
    "    \"\"\"\n",
    "    Résout le portefeuille de variance globale minimale (GMV).\n",
    "    \n",
    "    Problème d'optimisation: min w'Σw  s.c. sum w=1, bounds\n",
    "    \n",
    "    Args:\n",
    "        cov: matrice de covariance\n",
    "        w_bounds: tuple (lower_bounds, upper_bounds)\n",
    "        \n",
    "    Returns:\n",
    "        Résultat d'optimisation scipy avec attributs success, x, fun, etc.\n",
    "    \"\"\"\n",
    "    n = cov.shape[0]\n",
    "    \n",
    "    def obj(w): \n",
    "        return w @ cov @ w\n",
    "    \n",
    "    cons = [{\"type\": \"eq\", \"fun\": lambda w: np.sum(w) - 1.0}]\n",
    "    lb, ub = w_bounds\n",
    "    bounds = Bounds(lb, ub)\n",
    "    w0 = np.full(n, 1.0 / n)\n",
    "    \n",
    "    res = minimize(obj, w0, method=\"SLSQP\", bounds=bounds, constraints=cons)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5bb0d192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ┌─────────────────────────────────────┐\n",
    "# │        FRONTIÈRE EFFICIENTE         │ \n",
    "# └─────────────────────────────────────┘\n",
    "\n",
    "def efficient_frontier(mu, cov, w_bounds, n_pts=50) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Construit la frontière efficiente en balayant des rendements cibles.\n",
    "    \n",
    "    La frontière efficiente est l'ensemble des portefeuilles optimaux offrant\n",
    "    le rendement maximal pour chaque niveau de risque donné.\n",
    "    \n",
    "    Args:\n",
    "        mu: vecteur des rendements moyens\n",
    "        cov: matrice de covariance\n",
    "        w_bounds: tuple (lower_bounds, upper_bounds)\n",
    "        n_pts: nombre de points sur la frontière (défaut: 50)\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame avec colonnes: target_ret, ret, vol, weights\n",
    "    \"\"\"\n",
    "    # Point GMV pour la borne inférieure de la frontière\n",
    "    gmv_res = _global_min_var(cov, w_bounds)\n",
    "    if not gmv_res.success:\n",
    "        raise RuntimeError(\"Échec optimisation GMV.\")\n",
    "    \n",
    "    # Bornes des rendements cibles\n",
    "    mu_min = float(np.dot(mu, gmv_res.x))  # Rendement du GMV\n",
    "    mu_max = float(np.max(mu))  # Rendement de l'actif le plus performant\n",
    "    targets = np.linspace(mu_min, mu_max, n_pts)\n",
    "\n",
    "    rows = []\n",
    "    for t in targets:\n",
    "        res = _min_var_given_return(mu, cov, t, w_bounds, allow_short=False)\n",
    "        if res.success:\n",
    "            w = res.x\n",
    "            ret = float(mu @ w)\n",
    "            vol = float(np.sqrt(max(w @ cov @ w, 0)))  # Protection contre variance négative\n",
    "            rows.append({\n",
    "                \"target_ret\": t, \n",
    "                \"ret\": ret, \n",
    "                \"vol\": vol, \n",
    "                \"weights\": w\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(rows)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "159a1879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ┌─────────────────────────────────────┐\n",
    "# │      CONTRIBUTIONS DE RISQUE        │\n",
    "# └─────────────────────────────────────┘\n",
    "\n",
    "def risk_contributions(w, cov):\n",
    "    \"\"\"\n",
    "    Calcule les contributions de risque de chaque actif dans un portefeuille.\n",
    "    \n",
    "    La contribution de risque d'un actif i est définie comme:\n",
    "    RC_i = w_i * (Σw)_i = w_i * MRC_i\n",
    "    \n",
    "    où MRC_i est la contribution de risque marginale (Marginal Risk Contribution).\n",
    "    \n",
    "    Args:\n",
    "        w: vecteur des poids du portefeuille\n",
    "        cov: matrice de covariance des rendements\n",
    "        \n",
    "    Returns:\n",
    "        rc: vecteur des contributions de risque\n",
    "        port_var: variance totale du portefeuille\n",
    "    \"\"\"\n",
    "    w = np.asarray(w)\n",
    "    port_var = w @ cov @ w\n",
    "    mrc = cov @ w  # marginal risk contribution\n",
    "    rc = w * mrc\n",
    "    return rc, port_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "54199103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ┌─────────────────────────────────────┐\n",
    "# │    EQUAL RISK CONTRIBUTION (ERC)    │ \n",
    "# └─────────────────────────────────────┘\n",
    "\n",
    "def solve_erc(cov, w_bounds, tol=1e-8):\n",
    "    \"\"\"\n",
    "    Résout le portefeuille Equal Risk Contribution (ERC) ou Risk Parity.\n",
    "    \n",
    "    Le portefeuille ERC cherche à égaliser les contributions de risque de tous les actifs.\n",
    "    Problème d'optimisation: min Σᵢⱼ (RC_i - RC_j)²  s.c. Σwᵢ = 1, bounds\n",
    "    \n",
    "    où RC_i est la contribution de risque de l'actif i au risque total du portefeuille.\n",
    "    \n",
    "    Args:\n",
    "        cov: matrice de covariance des rendements\n",
    "        w_bounds: tuple (lower_bounds, upper_bounds) pour les contraintes de poids\n",
    "        tol: tolérance de convergence (défaut: 1e-8)\n",
    "        \n",
    "    Returns:\n",
    "        Résultat d'optimisation scipy avec attributs success, x, fun, etc.\n",
    "    \"\"\"\n",
    "    n = cov.shape[0]\n",
    "    lb, ub = w_bounds\n",
    "    bounds = Bounds(lb, ub)\n",
    "    cons = [{\"type\": \"eq\", \"fun\": lambda w: np.sum(w) - 1.0}]\n",
    "    w0 = np.full(n, 1.0 / n)  # Poids équipondérés comme point de départ\n",
    "\n",
    "    def obj(w):\n",
    "        rc, _ = risk_contributions(w, cov)\n",
    "        if np.any(w < 0):  # sécurité contre les poids négatifs\n",
    "            return 1e6\n",
    "        avg = np.mean(rc)\n",
    "        return np.sum((rc - avg) ** 2)  # Minimise la variance des contributions de risque\n",
    "\n",
    "    res = minimize(obj, w0, method=\"SLSQP\", bounds=bounds, constraints=cons, \n",
    "                   options={\"ftol\": tol, \"maxiter\": 500})\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8716d0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ┌─────────────────────────────────────┐\n",
    "# │   RÉPLICATION PORTEFEUILLE CIBLE    │ \n",
    "# └─────────────────────────────────────┘\n",
    "\n",
    "def replicate_target_portfolio(etf_rets: pd.DataFrame,\n",
    "                               target_rets: pd.Series,\n",
    "                               long_only: bool = True,\n",
    "                               sum_to_one: bool = True) -> Tuple[np.ndarray, dict]:\n",
    "    \"\"\"\n",
    "    Résout le problème de réplication d'un portefeuille cible (Mystery Allocation).\n",
    "    \n",
    "    Cette fonction trouve les poids optimaux des ETFs pour répliquer au mieux\n",
    "    les rendements d'un portefeuille cible en minimisant l'erreur quadratique.\n",
    "    \n",
    "    Problème d'optimisation: min_w ||R_ETF * w - R_target||²\n",
    "    s.c. (optionnel) w ≥ 0, Σw = 1\n",
    "    \n",
    "    Args:\n",
    "        etf_rets: DataFrame des rendements des ETFs (dates x ETFs)\n",
    "        target_rets: Série des rendements du portefeuille cible à répliquer\n",
    "        long_only: si True, impose des poids positifs uniquement (défaut: True)\n",
    "        sum_to_one: si True, impose que la somme des poids = 1 (défaut: True)\n",
    "        \n",
    "    Returns:\n",
    "        Tuple contenant:\n",
    "        - w: vecteur des poids optimaux (ou poids équipondérés si échec)\n",
    "        - info_optim: dictionnaire avec success, message, fun (erreur résiduelle)\n",
    "    \"\"\"\n",
    "    # Alignement des données sur les mêmes dates\n",
    "    XR, yR = etf_rets.align(target_rets, join=\"inner\", axis=0)\n",
    "    X = XR.values  # Matrice des rendements ETFs\n",
    "    y = yR.values  # Vecteur des rendements cibles\n",
    "\n",
    "    n = X.shape[1]  # Nombre d'ETFs\n",
    "    \n",
    "    def obj(w):\n",
    "        \"\"\"Fonction objectif: somme des carrés des résidus\"\"\"\n",
    "        resid = X @ w - y\n",
    "        return resid @ resid\n",
    "\n",
    "    # Configuration des contraintes\n",
    "    cons = []\n",
    "    if sum_to_one:\n",
    "        cons.append({\"type\": \"eq\", \"fun\": lambda w: np.sum(w) - 1.0})\n",
    "\n",
    "    # Configuration des bornes\n",
    "    if long_only:\n",
    "        lb, ub = np.zeros(n), np.ones(n)\n",
    "    else:\n",
    "        lb, ub = -np.inf * np.ones(n), np.inf * np.ones(n)\n",
    "    \n",
    "    bounds = Bounds(lb, ub)\n",
    "    w0 = np.full(n, 1.0 / n)  # Point de départ équipondéré\n",
    "\n",
    "    # Optimisation\n",
    "    res = minimize(obj, w0, method=\"SLSQP\", bounds=bounds, constraints=cons)\n",
    "    \n",
    "    # Retour des résultats\n",
    "    optimal_weights = res.x if res.success else w0\n",
    "    optimization_info = {\n",
    "        \"success\": res.success, \n",
    "        \"message\": res.message, \n",
    "        \"fun\": res.fun\n",
    "    }\n",
    "    \n",
    "    return optimal_weights, optimization_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "208e57ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fonction replicate_target_portfolio corrigée et mise à jour!\n"
     ]
    }
   ],
   "source": [
    "# ┌─────────────────────────────────────┐\n",
    "# │      CORRECTION D'ERREUR ALIGN      │ \n",
    "# └─────────────────────────────────────┘\n",
    "\n",
    "# Force la re-définition de la fonction corrigée\n",
    "def replicate_target_portfolio_fixed(etf_rets: pd.DataFrame,\n",
    "                                     target_rets: pd.Series,\n",
    "                                     long_only: bool = True,\n",
    "                                     sum_to_one: bool = True) -> Tuple[np.ndarray, dict]:\n",
    "    \"\"\"\n",
    "    Version corrigée de replicate_target_portfolio avec axis=0 spécifié.\n",
    "    \"\"\"\n",
    "    # Alignement des données sur les mêmes dates avec axis=0 explicite\n",
    "    common_idx = etf_rets.index.intersection(target_rets.index)\n",
    "    X = etf_rets.loc[common_idx].values  # Matrice des rendements ETFs\n",
    "    y = target_rets.loc[common_idx].values  # Vecteur des rendements cibles\n",
    "\n",
    "    n = X.shape[1]  # Nombre d'ETFs\n",
    "    \n",
    "    def obj(w):\n",
    "        \"\"\"Fonction objectif: somme des carrés des résidus\"\"\"\n",
    "        resid = X @ w - y\n",
    "        return resid @ resid\n",
    "\n",
    "    # Configuration des contraintes\n",
    "    cons = []\n",
    "    if sum_to_one:\n",
    "        cons.append({\"type\": \"eq\", \"fun\": lambda w: np.sum(w) - 1.0})\n",
    "\n",
    "    # Configuration des bornes\n",
    "    if long_only:\n",
    "        lb, ub = np.zeros(n), np.ones(n)\n",
    "    else:\n",
    "        lb, ub = -np.inf * np.ones(n), np.inf * np.ones(n)\n",
    "    \n",
    "    bounds = Bounds(lb, ub)\n",
    "    w0 = np.full(n, 1.0 / n)  # Point de départ équipondéré\n",
    "\n",
    "    # Optimisation\n",
    "    res = minimize(obj, w0, method=\"SLSQP\", bounds=bounds, constraints=cons)\n",
    "    \n",
    "    # Retour des résultats\n",
    "    optimal_weights = res.x if res.success else w0\n",
    "    optimization_info = {\n",
    "        \"success\": res.success, \n",
    "        \"message\": res.message, \n",
    "        \"fun\": res.fun\n",
    "    }\n",
    "    \n",
    "    return optimal_weights, optimization_info\n",
    "\n",
    "# Remplace la fonction originale\n",
    "replicate_target_portfolio = replicate_target_portfolio_fixed\n",
    "print(\"✅ Fonction replicate_target_portfolio corrigée et mise à jour!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6ac4e4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données...\n",
      "Calcul des rendements...\n",
      "Calcul des statistiques descriptives...\n",
      "Optimisation Markowitz...\n",
      "Calcul des rendements...\n",
      "Calcul des statistiques descriptives...\n",
      "Optimisation Markowitz...\n",
      "Construction de la frontière efficiente...\n",
      "Construction de la frontière efficiente...\n",
      "Optimisation Risk Parity...\n",
      "Mapping vers classes d'actifs...\n",
      "[INFO] Colonnes de mapping non détectées (Ticker/AssetClass).\n",
      "Réplication des allocations mystères...\n",
      "Optimisation Risk Parity...\n",
      "Mapping vers classes d'actifs...\n",
      "[INFO] Colonnes de mapping non détectées (Ticker/AssetClass).\n",
      "Réplication des allocations mystères...\n",
      "\n",
      "Analyse terminée! Résultats exportés dans: c:\\Users\\emman\\Documents\\GitHub\\Python-for-Optimization-in-Finance\\results\n",
      "\n",
      "Analyse terminée! Résultats exportés dans: c:\\Users\\emman\\Documents\\GitHub\\Python-for-Optimization-in-Finance\\results\n"
     ]
    }
   ],
   "source": [
    "# ┌─────────────────────────────────────┐\n",
    "# │        PIPELINE PRINCIPAL           │\n",
    "# └─────────────────────────────────────┘\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Pipeline principal d'analyse et d'optimisation de portefeuille.\n",
    "    \n",
    "    Ce script orchestre l'ensemble du processus d'analyse financière :\n",
    "    1. Chargement et préparation des données (ETFs, classes d'actifs, allocations mystères)\n",
    "    2. Calcul des rendements et statistiques descriptives\n",
    "    3. Optimisation de portefeuilles (Markowitz, Risk Parity)\n",
    "    4. Construction de la frontière efficiente\n",
    "    5. Mapping vers les classes d'actifs\n",
    "    6. Réplication des allocations mystères\n",
    "    7. Export des résultats et visualisations\n",
    "    \n",
    "    Données requises:\n",
    "        - Anonymized ETFs.csv: Prix historiques des 105 ETFs\n",
    "        - Main Asset Classes.csv: Mapping ETFs vers classes d'actifs\n",
    "        - Mystery Allocation 1.csv: Allocation mystère fixe\n",
    "        - Mystery Allocation 2.csv: Allocation mystère dynamique\n",
    "    \n",
    "    Sorties générées:\n",
    "        - CSV: statistiques, poids, performances, frontière efficiente\n",
    "        - PNG: graphiques de la frontière efficiente et réplications\n",
    "        - Excel: agrégation par classe d'actifs\n",
    "    \"\"\"\n",
    "    # ---------- 6.1) Chargement des données ----------\n",
    "    print(\"Chargement des données...\")\n",
    "    etf_path = \"Anonymized ETFs.csv\"\n",
    "    classes_path = \"Main Asset Classes.csv\"\n",
    "    mystery1_path = \"Mystery Allocation 1.csv\"\n",
    "    mystery2_path = \"Mystery Allocation 2.csv\"\n",
    "\n",
    "    etf_prices = load_csv_safely(etf_path)\n",
    "    classes_map = load_csv_safely(classes_path, parse_dates=False)\n",
    "    myst1_prices = load_csv_safely(mystery1_path)\n",
    "    myst2_prices = load_csv_safely(mystery2_path)\n",
    "\n",
    "    if etf_prices is None or etf_prices.empty:\n",
    "        print(\"[ERREUR] Anonymized ETFs introuvable ou vide. Abandon.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Harmonisation numérique\n",
    "    etf_prices = ensure_numeric(etf_prices)\n",
    "    if myst1_prices is not None:\n",
    "        myst1_prices = ensure_numeric(myst1_prices)\n",
    "    if myst2_prices is not None:\n",
    "        myst2_prices = ensure_numeric(myst2_prices)\n",
    "\n",
    "    # ---------- 6.2) Calcul des rendements ----------\n",
    "    print(\"Calcul des rendements...\")\n",
    "    etf_returns = to_returns(etf_prices, kind=\"simple\").dropna(how=\"all\")\n",
    "\n",
    "    # Rendements des allocations mystères (si disponibles)\n",
    "    myst1_returns = to_returns(myst1_prices, kind=\"simple\").iloc[:, 0] if myst1_prices is not None and myst1_prices.shape[1] >= 1 else None\n",
    "    myst2_returns = to_returns(myst2_prices, kind=\"simple\").iloc[:, 0] if myst2_prices is not None and myst2_prices.shape[1] >= 1 else None\n",
    "\n",
    "    # ---------- 6.3) Statistiques descriptives ----------\n",
    "    print(\"Calcul des statistiques descriptives...\")\n",
    "    periods = 252  # Fréquence quotidienne (jours ouvrables)\n",
    "    mu_ann, cov_ann = annualize_mean_vol(etf_returns, periods_per_year=periods)\n",
    "\n",
    "    # Export des statistiques de base par ETF\n",
    "    desc = pd.DataFrame({\n",
    "        \"mu_ann\": mu_ann,\n",
    "        \"vol_ann\": np.sqrt(np.diag(cov_ann)),\n",
    "    })\n",
    "    desc[\"sharpe_ann_rf0\"] = desc[\"mu_ann\"] / desc[\"vol_ann\"]\n",
    "    desc.to_csv(os.path.join(OUTPUT_DIR, \"stats_assets.csv\"))\n",
    "\n",
    "    # ---------- 6.4) Optimisation Markowitz (MVO) ----------\n",
    "    print(\"Optimisation Markowitz...\")\n",
    "    tickers = list(mu_ann.index)\n",
    "    n = len(tickers)\n",
    "    # Contraintes : long-only, somme=1, poids max 30% par actif\n",
    "    max_w = 0.30 if n >= 4 else 1.0\n",
    "    w_bounds = (np.zeros(n), np.full(n, max_w))\n",
    "\n",
    "    # Portefeuille de variance minimale globale (GMV)\n",
    "    gmv_res = _global_min_var(cov_ann.values, w_bounds)\n",
    "    gmv_w = gmv_res.x if gmv_res.success else np.full(n, 1.0 / n)\n",
    "\n",
    "    # Portefeuille de Sharpe maximal (rf=0)\n",
    "    ms_res = _max_sharpe(mu_ann.values, cov_ann.values, rf=0.0, w_bounds=w_bounds)\n",
    "    ms_w = ms_res.x if ms_res.success else np.full(n, 1.0 / n)\n",
    "\n",
    "    weights_gmv = pd.Series(gmv_w, index=tickers, name=\"GMV\")\n",
    "    weights_ms = pd.Series(ms_w, index=tickers, name=\"MaxSharpe\")\n",
    "\n",
    "    weights = pd.concat([weights_gmv, weights_ms], axis=1)\n",
    "    weights.to_csv(os.path.join(OUTPUT_DIR, \"weights_mvo.csv\"))\n",
    "\n",
    "    # Calcul des performances in-sample pour GMV & MaxSharpe\n",
    "    portfolios = {\n",
    "        \"GMV\": (etf_returns @ weights_gmv),\n",
    "        \"MaxSharpe\": (etf_returns @ weights_ms),\n",
    "    }\n",
    "\n",
    "    perf_rows = []\n",
    "    for name, rets in portfolios.items():\n",
    "        rep = compute_performance_stats(rets, rf=0.0, periods_per_year=periods)\n",
    "        perf_rows.append({\n",
    "            \"portfolio\": name, \"CAGR\": rep.cagr, \"Vol\": rep.vol,\n",
    "            \"Sharpe\": rep.sharpe, \"MaxDD\": rep.maxdd,\n",
    "            \"VaR95\": rep.var_95, \"ES95\": rep.es_95\n",
    "        })\n",
    "    pd.DataFrame(perf_rows).to_csv(os.path.join(OUTPUT_DIR, \"stats_portfolios.csv\"), index=False)\n",
    "\n",
    "    # ---------- 6.5) Construction de la frontière efficiente ----------\n",
    "    print(\"Construction de la frontière efficiente...\")\n",
    "    ef = efficient_frontier(mu_ann.values, cov_ann.values, w_bounds, n_pts=40)\n",
    "    ef[[\"ret\", \"vol\"]].to_csv(os.path.join(OUTPUT_DIR, \"efficient_frontier.csv\"), index=False)\n",
    "    \n",
    "    # Visualisation de la frontière efficiente\n",
    "    fig = plt.figure(figsize=(6.2, 4.2))\n",
    "    plt.plot(ef[\"vol\"], ef[\"ret\"], marker=\"o\", linestyle=\"-\", linewidth=1)\n",
    "    plt.scatter(np.sqrt(weights_gmv.values @ cov_ann.values @ weights_gmv.values),\n",
    "                float(mu_ann.values @ weights_gmv.values),\n",
    "                label=\"GMV\", s=40)\n",
    "    plt.scatter(np.sqrt(weights_ms.values @ cov_ann.values @ weights_ms.values),\n",
    "                float(mu_ann.values @ weights_ms.values),\n",
    "                label=\"Max Sharpe\", s=40)\n",
    "    plt.xlabel(\"Volatilité annualisée\")\n",
    "    plt.ylabel(\"Rendement annualisé\")\n",
    "    plt.title(\"Frontière Efficiente\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, \"efficient_frontier.png\"))\n",
    "    plt.close(fig)\n",
    "\n",
    "    # ---------- 6.6) Optimisation Risk Parity (ERC) ----------\n",
    "    print(\"Optimisation Risk Parity...\")\n",
    "    erc_res = solve_erc(cov_ann.values, w_bounds)\n",
    "    erc_w = erc_res.x if erc_res.success else np.full(n, 1.0 / n)\n",
    "    weights_erc = pd.Series(erc_w, index=tickers, name=\"ERC\")\n",
    "    weights_erc.to_csv(os.path.join(OUTPUT_DIR, \"weights_erc.csv\"))\n",
    "    portfolios[\"ERC\"] = etf_returns @ weights_erc\n",
    "    rep_erc = compute_performance_stats(portfolios[\"ERC\"], rf=0.0, periods_per_year=periods)\n",
    "\n",
    "    # Ajout d'ERC aux statistiques\n",
    "    df_stats = pd.read_csv(os.path.join(OUTPUT_DIR, \"stats_portfolios.csv\"))\n",
    "    df_stats = pd.concat([df_stats, pd.DataFrame([{\n",
    "        \"portfolio\": \"ERC\", \"CAGR\": rep_erc.cagr, \"Vol\": rep_erc.vol,\n",
    "        \"Sharpe\": rep_erc.sharpe, \"MaxDD\": rep_erc.maxdd,\n",
    "        \"VaR95\": rep_erc.var_95, \"ES95\": rep_erc.es_95\n",
    "    }])], ignore_index=True)\n",
    "    df_stats.to_csv(os.path.join(OUTPUT_DIR, \"stats_portfolios.csv\"), index=False)\n",
    "\n",
    "    # ---------- 6.7) Mapping vers classes d'actifs ----------\n",
    "    print(\"Mapping vers classes d'actifs...\")\n",
    "    if classes_map is not None and not classes_map.empty:\n",
    "        cm = classes_map.copy()\n",
    "        cm.columns = [c.strip() for c in cm.columns]\n",
    "        # Détection automatique des colonnes pertinentes\n",
    "        tick_col = next((c for c in cm.columns if \"tick\" in c.lower()), None)\n",
    "        class_col = next((c for c in cm.columns if \"class\" in c.lower()), None)\n",
    "        if tick_col and class_col:\n",
    "            asset_map = cm.set_index(tick_col)[class_col].to_dict()\n",
    "            # Agrégation des poids par classe d'actifs\n",
    "            def agg_by_class(w: pd.Series) -> pd.Series:\n",
    "                tmp = pd.DataFrame({\"Ticker\": w.index, \"Weight\": w.values})\n",
    "                tmp[\"AssetClass\"] = tmp[\"Ticker\"].map(asset_map).fillna(\"Unknown\")\n",
    "                return tmp.groupby(\"AssetClass\")[\"Weight\"].sum().sort_values(ascending=False)\n",
    "            \n",
    "            agg = {\n",
    "                \"GMV\": agg_by_class(weights_gmv),\n",
    "                \"MaxSharpe\": agg_by_class(weights_ms),\n",
    "                \"ERC\": agg_by_class(weights_erc)\n",
    "            }\n",
    "            # Export vers Excel\n",
    "            with pd.ExcelWriter(os.path.join(OUTPUT_DIR, \"weights_by_asset_class.xlsx\")) as xw:\n",
    "                for name, s in agg.items():\n",
    "                    s.to_frame(\"Weight\").to_excel(xw, sheet_name=name)\n",
    "        else:\n",
    "            print(\"[INFO] Colonnes de mapping non détectées (Ticker/AssetClass).\")\n",
    "\n",
    "    # ---------- 6.8) Réplication des allocations mystères ----------\n",
    "    print(\"Réplication des allocations mystères...\")\n",
    "    def replicate_and_report(target_prices: Optional[pd.DataFrame], tag: str):\n",
    "        if target_prices is None or target_prices.empty:\n",
    "            print(f\"[INFO] {tag}: pas de données cibles.\")\n",
    "            return\n",
    "        target_rets = to_returns(target_prices, kind=\"simple\").iloc[:, 0]\n",
    "        # Alignement des données sur les mêmes dates\n",
    "        er = etf_returns.copy()\n",
    "        common_idx = er.index.intersection(target_rets.index)\n",
    "        er = er.loc[common_idx]\n",
    "        tr = target_rets.loc[common_idx]\n",
    "\n",
    "        w_rep, info = replicate_target_portfolio(er, tr, long_only=True, sum_to_one=True)\n",
    "        w_ser = pd.Series(w_rep, index=er.columns, name=f\"Replicated_{tag}\")\n",
    "        w_ser.to_csv(os.path.join(OUTPUT_DIR, f\"weights_replication_{tag}.csv\"))\n",
    "\n",
    "        # Métriques de qualité d'ajustement\n",
    "        fitted = (er @ w_ser).rename(f\"Rep_{tag}\")\n",
    "        te = (fitted - tr).std() * np.sqrt(periods)  # Tracking Error annualisé\n",
    "        r2 = 1 - ((fitted - tr).var() / tr.var()) if tr.var() > 0 else np.nan\n",
    "\n",
    "        # Statistiques de performance du portefeuille répliqué\n",
    "        rep_stats = compute_performance_stats(fitted, rf=0.0, periods_per_year=periods)\n",
    "        out = {\n",
    "            \"Target\": tag,\n",
    "            \"Rep_success\": info.get(\"success\", False),\n",
    "            \"Rep_message\": info.get(\"message\", \"\"),\n",
    "            \"TrackingError_ann\": te,\n",
    "            \"R2\": r2,\n",
    "            \"CAGR\": rep_stats.cagr,\n",
    "            \"Vol\": rep_stats.vol,\n",
    "            \"Sharpe\": rep_stats.sharpe,\n",
    "            \"MaxDD\": rep_stats.maxdd,\n",
    "        }\n",
    "        dfout = pd.DataFrame([out])\n",
    "        csv_path = os.path.join(OUTPUT_DIR, f\"replication_report_{tag}.csv\")\n",
    "        if os.path.exists(csv_path):\n",
    "            prev = pd.read_csv(csv_path)\n",
    "            dfout = pd.concat([prev, dfout], ignore_index=True)\n",
    "        dfout.to_csv(csv_path, index=False)\n",
    "\n",
    "        # Visualisation des performances cumulées\n",
    "        fig = plt.figure(figsize=(6.6, 4))\n",
    "        (1 + tr).cumprod().plot(label=f\"Target {tag}\")\n",
    "        (1 + fitted).cumprod().plot(label=f\"Replicated {tag}\")\n",
    "        plt.title(f\"Réplication — {tag}\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(OUTPUT_DIR, f\"replication_{tag}.png\"))\n",
    "        plt.close(fig)\n",
    "\n",
    "    replicate_and_report(myst1_prices, \"Mystery1\")\n",
    "    replicate_and_report(myst2_prices, \"Mystery2\")\n",
    "\n",
    "    print(f\"\\nAnalyse terminée! Résultats exportés dans: {os.path.abspath(OUTPUT_DIR)}\")\n",
    "\n",
    "\n",
    "# Point d'entrée principal\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
